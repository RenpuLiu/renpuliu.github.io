---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Education
======
* **University of Virginia**, Charlottesville, VA, USA
  * Ph.D. [cite_start]Candidate in Electrical Engineering (Expected May 2026) [cite: 4]
  * *Jan. [cite_start]2025 - Present* [cite: 4]

* **Pennsylvania State University**, State College, PA, USA
  * Ph.D. [cite_start]Student in Electrical and Electronics Engineering [cite: 4]
  * *Sep. [cite_start]2021 - Dec. 2024* [cite: 4]

* **University of Pennsylvania**, Philadelphia, PA, USA
  * [cite_start]M.S.E. in Electrical Engineering [cite: 4]
  * *Aug. [cite_start]2019 - May 2021* [cite: 4]

* **Nanjing University**, Nanjing, Jiangsu, China
  * [cite_start]B.S. in Electronic Information Science and Technology [cite: 4]
  * *Sep. [cite_start]2015 - Jun. 2019* [cite: 4]

Research Interests
======
* [cite_start]**Large Language Models (LLMs):** Transformers, In-context learning (ICL), Chain-of-Thought (CoT) [cite: 6, 7, 35]
* [cite_start]**Reinforcement Learning:** RLHF, Personalized RLHF, Low-Rank Adaptation (LoRA) [cite: 8, 29]
* [cite_start]**Distributed Learning:** Federated Learning, Representation Learning, Heterogeneity [cite: 9, 10, 17]

Selected Publications
======
**Conference Proceedings**
* **[NeurIPS 2025]** **Renpu Liu**, Jing Yang. "Unlabeled Data Can Provably Enhance In-Context Learning of Transformers." [cite_start]*The 39th Annual Conference on Neural Information Processing Systems*. [cite: 44, 45, 46]
* **[ICLR 2025]** **Renpu Liu***, Ruida Zhou*, Cong Shen, and Jing Yang. "On the Learn-to-Optimize Capabilities of Transformers in In-Context Sparse Recovery." [cite_start]*The 13th International Conference on Learning Representations*. [cite: 53, 54, 55]
* **[AISTATS 2025]** **Renpu Liu**, Peng Wang, Donghao Li, Cong Shen, Jing Yang. "A Shared Low-Rank Adaptation Approach to Personalized RLHF." [cite_start]*The 28th International Conference on Artificial Intelligence and Statistics*. [cite: 50, 51, 52]
* **[ICML 2024]** **Renpu Liu**, Cong Shen, and Jing Yang. "Federated Representation Learning in the Under-Parameterized Regime." [cite_start]*The 41st International Conference on Machine Learning*. [cite: 56, 57, 58]
* **[ISIT 2025]** **Renpu Liu**, Liwen Zhong, Wooram Lee, and Jing Yang. "In-Context Learning Based Efficient Spectrum Sensing." [cite_start]*IEEE International Symposium on Information Theory*. [cite: 47, 48, 49]
* **[ISIT 2023]** **Renpu Liu**, Jing Yang, and Cong Shen. "Exploiting Feature Heterogeneity for Improved Generalization in Federated Multi-task Learning." [cite_start]*IEEE International Symposium on Information Theory*. [cite: 59, 60]
* **[ISIT 2021]** Xingran Chen, **Renpu Liu**, Shaochong Wang, and Shirin Saeedi Bidokhti. "Timely Broadcasting in Erasure Networks: Age-Rate Tradeoffs." [cite_start]*IEEE International Symposium on Information Theory*. [cite: 61, 62]

**Under Review**
* **[ICASSP 2026]** Li Fan, Zhoubin Kou, **Renpu Liu**, Jing Yang and Cong Shen. [cite_start]"Augmented In-Context Learning for Wireless Symbol Detection." [cite: 65, 66, 67]
* **[ICASSP 2026]** Zhoubin Kou, **Renpu Liu**, Cong Shen and Jing Yang. [cite_start]"Multi-task Transformer-Based Receiver for OFDM Channel Estimation and Symbol Detection." [cite: 63, 64]

Research Experience
======
**University of Virginia / Pennsylvania State University**
*Research Assistant (Advisor: Prof. Jing Yang)*
*Sep. [cite_start]2021 - Present* [cite: 12, 13, 14]
* [cite_start]**In-Context Learning & Optimization:** Proved that unlabeled data enhances ICL performance and developed a framework where Transformers emulate iterative refinement (CoT)[cite: 33, 34, 35]. [cite_start]Demonstrated that Transformers can implement LISTA-type learning-to-optimize algorithms for sparse recovery[cite: 26].
* [cite_start]**Personalized RLHF:** Proposed a framework using shared Low-Rank Adaptation (LoRA) to capture user-specific preferences while reducing sample complexity[cite: 29, 30].
* [cite_start]**Federated Learning:** Developed algorithms for Federated Representation Learning in under-parameterized regimes and exploited feature heterogeneity to improve generalization[cite: 17, 22].

**University of Pennsylvania**
*Research Assistant (Advisor: Prof. Shirin Saeedi Bidokhti)*
*Aug. [cite_start]2019 - May 2021* [cite: 37, 38, 40]
* [cite_start]**Information Theory:** Investigated Age of Information (AoI) and rate tradeoffs in broadcast channels[cite: 39, 41].
* [cite_start]Developed simulation scripts to analyze coding policies[cite: 43].